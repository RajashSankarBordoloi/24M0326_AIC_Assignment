{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11767343,"sourceType":"datasetVersion","datasetId":7387473}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:08:50.111170Z","iopub.execute_input":"2025-05-11T11:08:50.111420Z","iopub.status.idle":"2025-05-11T11:08:51.870984Z","shell.execute_reply.started":"2025-05-11T11:08:50.111396Z","shell.execute_reply":"2025-05-11T11:08:51.870203Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dataset-1/train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import f1_score, classification_report\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorWithPadding\n)\nfrom datasets import Dataset, ClassLabel\nfrom torch.utils.data import DataLoader, WeightedRandomSampler\nimport gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:09:32.863671Z","iopub.execute_input":"2025-05-11T11:09:32.864346Z","iopub.status.idle":"2025-05-11T11:10:00.301189Z","shell.execute_reply.started":"2025-05-11T11:09:32.864321Z","shell.execute_reply":"2025-05-11T11:10:00.300625Z"}},"outputs":[{"name":"stderr","text":"2025-05-11 11:09:46.591145: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746961786.803884      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746961786.864918      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Configuration \nclass CFG:\n    model_name = \"bert-base-uncased\"\n    max_length = 256\n    batch_size = 32\n    num_epochs = 4\n    learning_rate = 2e-5\n    seed = 42\n    text_col = \"text\"\n    label_col = \"labels\"\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    mixed_precision = True\n    gamma = 2.0  # Focal loss parameter\n    label_smoothing = 0.1  # Reduces overconfidence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:10:43.259311Z","iopub.execute_input":"2025-05-11T11:10:43.259563Z","iopub.status.idle":"2025-05-11T11:10:43.264176Z","shell.execute_reply.started":"2025-05-11T11:10:43.259547Z","shell.execute_reply":"2025-05-11T11:10:43.263221Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Data Preparation\ndf = pd.read_csv(\"/kaggle/input/dataset-1/train.csv\")\ndf = df.rename(columns={\"Category\": CFG.label_col, \"Text\": CFG.text_col})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:46:27.193110Z","iopub.execute_input":"2025-05-11T11:46:27.193900Z","iopub.status.idle":"2025-05-11T11:46:27.679970Z","shell.execute_reply.started":"2025-05-11T11:46:27.193871Z","shell.execute_reply":"2025-05-11T11:46:27.679181Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Remove duplicates based on text only (optional: keep first or use groupby)\ndf = df.drop_duplicates(subset=CFG.text_col).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:46:29.861790Z","iopub.execute_input":"2025-05-11T11:46:29.862340Z","iopub.status.idle":"2025-05-11T11:46:29.883476Z","shell.execute_reply.started":"2025-05-11T11:46:29.862315Z","shell.execute_reply":"2025-05-11T11:46:29.882743Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Convert to Dataset\ndataset = Dataset.from_pandas(df)\nclass_labels = ClassLabel(\n    num_classes=len(df[CFG.label_col].unique()),\n    names=list(df[CFG.label_col].unique())\n)\ndataset = dataset.cast_column(CFG.label_col, class_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:46:42.238134Z","iopub.execute_input":"2025-05-11T11:46:42.238867Z","iopub.status.idle":"2025-05-11T11:46:42.743136Z","shell.execute_reply.started":"2025-05-11T11:46:42.238840Z","shell.execute_reply":"2025-05-11T11:46:42.742624Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/12085 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea82e8bae0ad4ea7b4bcb7e4623fbea2"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Stratified split\nsplits = dataset.train_test_split(test_size=0.2, stratify_by_column=CFG.label_col, seed=CFG.seed)\ntrain_val = splits[\"train\"].train_test_split(test_size=0.125, stratify_by_column=CFG.label_col, seed=CFG.seed)\ndataset = {\n    \"train\": train_val[\"train\"],\n    \"valid\": train_val[\"test\"],\n    \"test\": splits[\"test\"]\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:01.704513Z","iopub.execute_input":"2025-05-11T11:47:01.705042Z","iopub.status.idle":"2025-05-11T11:47:01.797307Z","shell.execute_reply.started":"2025-05-11T11:47:01.705010Z","shell.execute_reply":"2025-05-11T11:47:01.796725Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# Tokenization\ntokenizer = AutoTokenizer.from_pretrained(CFG.model_name)\ntokenized_datasets = {\n    k: v.map(\n        lambda x: tokenizer(x[\"text\"], truncation=True, max_length=CFG.max_length, padding=False),\n        batched=True,\n        remove_columns=[\"text\"]\n    ) for k, v in dataset.items()\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:25.981745Z","iopub.execute_input":"2025-05-11T11:47:25.982523Z","iopub.status.idle":"2025-05-11T11:47:38.846980Z","shell.execute_reply.started":"2025-05-11T11:47:25.982496Z","shell.execute_reply":"2025-05-11T11:47:38.846282Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8459 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcf57a40bbba4e1094c7f323d3d837a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1209 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72a86200045349e094ea3ac40faaccf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2417 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"541588b82e214f6f898dc1cca280524e"}},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"# Adaptive Class Balancing\ntrain_labels = np.array(dataset[\"train\"][CFG.label_col])\nclass_counts = np.bincount(train_labels)\nclass_weights = 1. / (class_counts + 1e-6)  # Add smoothing\nsample_weights = class_weights[train_labels]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:43.045542Z","iopub.execute_input":"2025-05-11T11:47:43.046207Z","iopub.status.idle":"2025-05-11T11:47:43.087289Z","shell.execute_reply.started":"2025-05-11T11:47:43.046186Z","shell.execute_reply":"2025-05-11T11:47:43.086685Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# Create balanced sampler\nsampler = WeightedRandomSampler(\n    sample_weights, \n    num_samples=len(sample_weights),\n    replacement=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:45.345379Z","iopub.execute_input":"2025-05-11T11:47:45.345665Z","iopub.status.idle":"2025-05-11T11:47:45.349469Z","shell.execute_reply.started":"2025-05-11T11:47:45.345644Z","shell.execute_reply":"2025-05-11T11:47:45.348866Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Model Initialization\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    CFG.model_name,\n    num_labels=len(class_labels.names),\n    ignore_mismatched_sizes=True\n).to(CFG.device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:48.112642Z","iopub.execute_input":"2025-05-11T11:47:48.113314Z","iopub.status.idle":"2025-05-11T11:47:48.542864Z","shell.execute_reply.started":"2025-05-11T11:47:48.113290Z","shell.execute_reply":"2025-05-11T11:47:48.542333Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"# Custom Trainer with Focal Loss + Label Smoothing\nclass AdaptiveTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        labels = inputs.get(\"labels\")\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n        # Calculate cross entropy loss\n        ce_loss = torch.nn.functional.cross_entropy(\n            logits.view(-1, model.config.num_labels),\n            labels.view(-1),\n            reduction='none'\n        )\n        \n        # Focal loss component\n        pt = torch.exp(-ce_loss)\n        focal_loss = (1 - pt) ** CFG.gamma * ce_loss\n        \n        # Label smoothing regularization\n        smooth_loss = (1 - CFG.label_smoothing) * focal_loss.mean() + \\\n                     CFG.label_smoothing * (-torch.log_softmax(logits, dim=-1).mean())\n        \n        return (smooth_loss, outputs) if return_outputs else smooth_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:51.607721Z","iopub.execute_input":"2025-05-11T11:47:51.607990Z","iopub.status.idle":"2025-05-11T11:47:51.613765Z","shell.execute_reply.started":"2025-05-11T11:47:51.607971Z","shell.execute_reply":"2025-05-11T11:47:51.612982Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# Training Arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=CFG.learning_rate,\n    per_device_train_batch_size=CFG.batch_size,\n    per_device_eval_batch_size=CFG.batch_size*2,\n    num_train_epochs=CFG.num_epochs,\n    weight_decay=0.01,\n    logging_steps=50,\n    fp16=CFG.mixed_precision,\n    gradient_accumulation_steps=2,\n    warmup_ratio=0.1,\n    save_strategy=\"no\",\n    load_best_model_at_end=False,\n    report_to=\"none\",\n    optim=\"adamw_torch\",\n    seed=CFG.seed,\n    max_grad_norm=1.0  # Gradient clipping\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:54.240669Z","iopub.execute_input":"2025-05-11T11:47:54.240942Z","iopub.status.idle":"2025-05-11T11:47:54.266848Z","shell.execute_reply.started":"2025-05-11T11:47:54.240922Z","shell.execute_reply":"2025-05-11T11:47:54.266361Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"# Data Collator\ndata_collator = DataCollatorWithPadding(\n    tokenizer=tokenizer,\n    padding=\"longest\",\n    max_length=CFG.max_length\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:56.179745Z","iopub.execute_input":"2025-05-11T11:47:56.180347Z","iopub.status.idle":"2025-05-11T11:47:56.183841Z","shell.execute_reply.started":"2025-05-11T11:47:56.180323Z","shell.execute_reply":"2025-05-11T11:47:56.183295Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Initialize Trainer\ntrainer = AdaptiveTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"valid\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:47:58.224017Z","iopub.execute_input":"2025-05-11T11:47:58.224324Z","iopub.status.idle":"2025-05-11T11:47:58.237524Z","shell.execute_reply.started":"2025-05-11T11:47:58.224303Z","shell.execute_reply":"2025-05-11T11:47:58.236920Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2612256611.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AdaptiveTrainer.__init__`. Use `processing_class` instead.\n  trainer = AdaptiveTrainer(\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# Add balanced sampling\ntrainer.train_dataset = trainer.train_dataset.with_format(\"torch\")\ntrainer.train_dataloader = DataLoader(\n    trainer.train_dataset,\n    batch_size=CFG.batch_size,\n    sampler=sampler,\n    collate_fn=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:48:13.196774Z","iopub.execute_input":"2025-05-11T11:48:13.197062Z","iopub.status.idle":"2025-05-11T11:48:13.202704Z","shell.execute_reply.started":"2025-05-11T11:48:13.197041Z","shell.execute_reply":"2025-05-11T11:48:13.201941Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Clean memory\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:48:15.502072Z","iopub.execute_input":"2025-05-11T11:48:15.502348Z","iopub.status.idle":"2025-05-11T11:48:16.073997Z","shell.execute_reply.started":"2025-05-11T11:48:15.502329Z","shell.execute_reply":"2025-05-11T11:48:16.073433Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:48:18.809950Z","iopub.execute_input":"2025-05-11T11:48:18.810227Z","iopub.status.idle":"2025-05-11T12:01:23.642804Z","shell.execute_reply.started":"2025-05-11T11:48:18.810205Z","shell.execute_reply":"2025-05-11T12:01:23.642099Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='528' max='528' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [528/528 13:03, Epoch 3/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.084300</td>\n      <td>2.112372</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.521900</td>\n      <td>1.197316</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.981200</td>\n      <td>0.947444</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=528, training_loss=1.7470247745513916, metrics={'train_runtime': 784.4483, 'train_samples_per_second': 43.134, 'train_steps_per_second': 0.673, 'total_flos': 4426235859681792.0, 'train_loss': 1.7470247745513916, 'epoch': 3.9735849056603776})"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"# Evaluation\ndef compute_metrics(p):\n    preds = p.predictions.argmax(-1)\n    return {\n        \"macro_f1\": f1_score(p.label_ids, preds, average=\"macro\"),\n        \"weighted_f1\": f1_score(p.label_ids, preds, average=\"weighted\")\n    }\n\ntrainer.compute_metrics = compute_metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:02:30.767434Z","iopub.execute_input":"2025-05-11T12:02:30.768045Z","iopub.status.idle":"2025-05-11T12:02:30.771979Z","shell.execute_reply.started":"2025-05-11T12:02:30.768014Z","shell.execute_reply":"2025-05-11T12:02:30.771446Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Validation results\nvalid_results = trainer.evaluate()\nprint(\"\\nValidation Results:\")\nprint(f\"Macro F1: {valid_results['eval_macro_f1']:.4f}\")\nprint(f\"Weighted F1: {valid_results['eval_weighted_f1']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:02:49.383085Z","iopub.execute_input":"2025-05-11T12:02:49.383394Z","iopub.status.idle":"2025-05-11T12:02:58.409228Z","shell.execute_reply.started":"2025-05-11T12:02:49.383373Z","shell.execute_reply":"2025-05-11T12:02:58.408624Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nValidation Results:\nMacro F1: 0.8461\nWeighted F1: 0.8608\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"# Test results\ntest_results = trainer.predict(tokenized_datasets[\"test\"])\nprint(\"\\nTest Classification Report:\")\nprint(classification_report(\n    test_results.label_ids,\n    test_results.predictions.argmax(-1),\n    target_names=class_labels.names\n))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T12:03:08.176007Z","iopub.execute_input":"2025-05-11T12:03:08.176304Z","iopub.status.idle":"2025-05-11T12:03:26.168973Z","shell.execute_reply.started":"2025-05-11T12:03:08.176282Z","shell.execute_reply":"2025-05-11T12:03:26.168298Z"}},"outputs":[{"name":"stdout","text":"\nTest Classification Report:\n                           precision    recall  f1-score   support\n\n               Accountant       0.93      0.99      0.96        67\n                 Advocate       0.92      0.96      0.94        56\n              Agriculture       0.89      0.87      0.88        45\n                  Apparel       0.81      0.81      0.81        63\n             Architecture       0.86      0.82      0.84        61\n                     Arts       0.79      0.84      0.82        50\n               Automobile       0.80      0.58      0.67        60\n                 Aviation       0.96      0.98      0.97        65\n                  Banking       0.95      0.91      0.93        58\n               Blockchain       1.00      1.00      1.00         9\n                      BPO       0.85      0.56      0.68        39\nBuilding and Construction       0.78      0.87      0.82        67\n         Business Analyst       0.89      0.90      0.90        62\n           Civil Engineer       0.94      0.95      0.94        62\n               Consultant       0.84      0.83      0.83        69\n             Data Science       0.93      0.91      0.92        55\n                 Database       0.84      0.77      0.80        48\n                Designing       0.82      0.73      0.77        49\n                   DevOps       0.96      0.98      0.97        50\n            Digital Media       0.88      0.87      0.87        68\n         DotNet Developer       0.88      0.90      0.89        58\n                Education       0.94      0.87      0.91        78\n   Electrical Engineering       0.96      0.93      0.94        72\n            ETL Developer       0.76      0.76      0.76        51\n                  Finance       0.78      0.92      0.85        66\n       Food and Beverages       0.89      0.86      0.88        29\n       Health and Fitness       0.85      0.78      0.81        59\n          Human Resources       0.88      0.95      0.91        61\n   Information Technology       0.77      0.79      0.78        52\n           Java Developer       0.74      1.00      0.85        61\n               Management       0.78      0.45      0.57        64\n      Mechanical Engineer       0.97      1.00      0.99        67\nNetwork Security Engineer       0.88      0.98      0.93        61\n       Operations Manager       0.89      0.95      0.92        65\n                      PMO       0.62      0.76      0.68        49\n         Public Relations       0.94      0.97      0.95        62\n         Python Developer       0.83      0.69      0.75        42\n          React Developer       0.83      0.23      0.36        22\n                    Sales       0.62      0.74      0.67        68\n            SAP Developer       0.83      1.00      0.90        57\n            SQL Developer       0.81      0.84      0.82        50\n                  Testing       0.95      0.91      0.93        64\n            Web Designing       0.87      0.84      0.85        56\n\n                 accuracy                           0.86      2417\n                macro avg       0.86      0.84      0.84      2417\n             weighted avg       0.86      0.86      0.85      2417\n\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}