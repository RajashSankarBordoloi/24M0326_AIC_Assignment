{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6911caea-6bbe-4a17-8238-50c954b4a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2 pdfplumber langchain faiss-cpu sentence-transformers groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2170dd-98bb-4a10-91eb-b6c7785fe2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12440ddf-ee59-40f4-a8f5-e46498855a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def parse_pdf(pdf_path: str) -> str:\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            # Extract text and clean whitespace\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text.strip() + \"\\n\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5280e7d2-6d7c-4550-98fe-d55d6d0e8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = parse_pdf(\"AICommunity_Assignment_25.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f569f730-1501-484c-9dc3-ba4f4b5a446f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_text(text: str, chunk_size=500, chunk_overlap=50) -> list[str]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Split on paragraphs first\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "chunks = chunk_text(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cdd749a6-09ae-4a29-bb83-035848d6b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def build_index(chunks: list[str]) -> FAISS:\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    return FAISS.from_texts(chunks, embeddings)\n",
    "\n",
    "vector_db = build_index(chunks)\n",
    "vector_db.save_local(\"faiss_index\")  # Save for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "973e9d1f-b4a7-4f90-baa1-22cd9e4df743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query: str, vector_db: FAISS, k=3) -> list[str]:\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": k})\n",
    "    return retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33a2a742-4f42-4867-886e-479e94e99801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "def generate_answer(query: str, context: list, model: str = \"llama3-70b-8192\") -> str:\n",
    "    \"\"\"\n",
    "    Generates answers using Mistral-Saba-24B model via Groq API.\n",
    "    \n",
    "    Args:\n",
    "        query: User question\n",
    "        context: List of retrieved text chunks\n",
    "        model: Model name (confirm exact name via Groq console)\n",
    "    \n",
    "    Returns:\n",
    "        Generated answer string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        client = Groq(api_key=\"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\")  # Replace with your key\n",
    "        \n",
    "        context_str = \"\\n\\n\".join([c.page_content for c in context])  # Join chunks\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"\"\"Answer ONLY using the context below. If unsure, say \"I don't know\".\n",
    "                    \n",
    "                    Context:\n",
    "                    {context_str}\n",
    "                    \"\"\"\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            model=model,\n",
    "            temperature=0.3,  # Balance creativity/factuality\n",
    "            max_tokens=512     # Control response length\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error generating answer: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe615f5e-f4cd-4d27-b3ae-777f16a72092",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the first question in the document?\"\n",
    "context_chunks = retrieve_context(query, vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "552b7236-9302-4418-81c1-f60fb6f47fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know. The document does not explicitly state the first question. It provides general guidelines and instructions for the assignment.\n"
     ]
    }
   ],
   "source": [
    "answer = generate_answer(query, context_chunks)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aa1c706-5109-413b-a331-dc44087daae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = Groq(api_key=\"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\")\n",
    "# models = client.models.list()\n",
    "\n",
    "# for model in models.data:\n",
    "#     print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca0041-3e20-4de6-918a-4e406e3cbc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
