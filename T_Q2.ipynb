{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning for Fashion-MNIST with ResNet50\n",
    "\n",
    "This notebook implements transfer learning for classifying Fashion-MNIST images using a pretrained ResNet50 model. The dataset is in CSV format (`fashion-mnist_train.csv`, `fashion-mnist_test.csv`), with each row containing a `label` (0–9) and 784 pixel values (`pixel1`–`pixel784`) for a 28×28 grayscale image. We adapt ResNet50, train a custom head, fine-tune deeper layers, and visualize results.\n",
    "\n",
    "## Objectives\n",
    "- Load and validate the CSV dataset.\n",
    "- Analyze dataset characteristics (class distribution, pixel stats, sample images).\n",
    "- Preprocess images (resize to 224×224, convert to 3 channels, augment).\n",
    "- Train a custom head on pretrained ResNet50, then fine-tune deeper layers.\n",
    "- Display training and validation metrics per epoch for explainability.\n",
    "- Visualize training progress and performance with plots.\n",
    "- Optimize for a 16 GB GPU.\n",
    "\n",
    "## Hardware\n",
    "- **GPU**: 16 GB (e.g., NVIDIA RTX 3060).\n",
    "- **Optimizations**: Mixed precision training, batch size of 32, `pin_memory=True`, selective layer unfreezing.\n",
    "\n",
    "## Why Per-Epoch Metrics?\n",
    "Displaying training and validation loss, accuracy, and GPU memory usage per epoch:\n",
    "- **Explainability**: Shows model convergence and performance trends in real-time.\n",
    "- **Debugging**: Helps detect overfitting (large train-val accuracy gap), underfitting (high loss), or memory issues.\n",
    "- **Optimization**: Confirms GPU usage stays within 16 GB (~8–10 GB expected)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Imports\n",
    "\n",
    "We install dependencies, import libraries, and configure the environment. Logging captures metrics and GPU memory usage, and random seeds ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run if needed)\n",
    "!pip install torch torchvision pandas numpy matplotlib seaborn scikit-learn pillow\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename=f'fashion_mnist_training_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "# Log initial GPU memory\n",
    "if device.type == \"cuda\":\n",
    "    logging.info(f\"GPU Memory Allocated: {torch.cuda.memory_allocated(device)/1e6:.2f} MB\")\n",
    "    logging.info(f\"GPU Memory Cached: {torch.cuda.memory_reserved(device)/1e6:.2f} MB\")\n",
    "    print(f\"Initial GPU Memory Allocated: {torch.cuda.memory_allocated(device)/1e6:.2f} MB\")\n",
    "\n",
    "# Class names for Fashion-MNIST\n",
    "class_names = [\n",
    "    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n",
    "]\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Dataset Loading and Validation\n",
    "\n",
    "We define a `FashionMNISTCSVDataset` class to load the CSV files (785 columns: 1 `label`, 784 pixels). Validation ensures the correct format, preventing errors. A sample of the data is displayed to verify structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTCSVDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        # Validate dataset format\n",
    "        expected_columns = 785  # 1 label + 784 pixels\n",
    "        if len(self.data.columns) != expected_columns:\n",
    "            raise ValueError(f\"Expected {expected_columns} columns, got {len(self.data.columns)}\")\n",
    "        if 'label' not in self.data.columns:\n",
    "            raise ValueError(\"CSV must contain a 'label' column\")\n",
    "        pixel_cols = [col for col in self.data.columns if col.startswith('pixel')]\n",
    "        if len(pixel_cols) != 784:\n",
    "            raise ValueError(f\"Expected 784 pixel columns, got {len(pixel_cols)}\")\n",
    "        pixel_values = self.data[pixel_cols].values\n",
    "        if pixel_values.min() < 0 or pixel_values.max() > 255:\n",
    "            raise ValueError(\"Pixel values must be in range [0, 255]\")\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.labels = self.data['label'].values\n",
    "        self.images = self.data[pixel_cols].values.reshape(-1, 28, 28).astype(np.uint8)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.fromarray(image, mode='L')  # Grayscale image\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Check CSV files exist\n",
    "train_csv = 'fashion-mnist_train.csv'\n",
    "test_csv = 'fashion-mnist_test.csv'\n",
    "if not (os.path.exists(train_csv) and os.path.exists(test_csv)):\n",
    "    raise FileNotFoundError(\"CSV files not found. Please check the file paths.\")\n",
    "\n",
    "# Display sample data\n",
    "sample_data = pd.read_csv(train_csv, nrows=5)\n",
    "print(\"Sample of training data (first 5 rows, first 10 columns):\")\n",
    "print(sample_data.iloc[:, :10])  # Show label and first 9 pixels\n",
    "print(f\"Training set size: {len(pd.read_csv(train_csv))} images\")\n",
    "print(f\"Test set size: {len(pd.read_csv(test_csv))} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Analysis\n",
    "\n",
    "We analyze the training dataset to understand its properties:\n",
    "- **Class Distribution**: Plots a histogram to check if classes are balanced (~6,000 images per class).\n",
    "- **Pixel Statistics**: Computes mean and std to inform normalization.\n",
    "- **Sample Images**: Visualizes 10 images to confirm data integrity.\n",
    "\n",
    "These plots provide insights into the dataset’s structure and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset(train_csv):\n",
    "    data = pd.read_csv(train_csv)\n",
    "    pixel_cols = [col for col in data.columns if col.startswith('pixel')]\n",
    "    labels = data['label'].values\n",
    "    images = data[pixel_cols].values.reshape(-1, 28, 28)\n",
    "    \n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x=labels)\n",
    "    plt.title('Class Distribution in Fashion-MNIST Training Set')\n",
    "    plt.xticks(ticks=range(10), labels=class_names, rotation=45)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "    logging.info(\"Class distribution plot displayed\")\n",
    "    \n",
    "    # Compute pixel statistics\n",
    "    mean_pixel = images.mean() / 255.0\n",
    "    std_pixel = images.std() / 255.0\n",
    "    logging.info(f\"Pixel mean: {mean_pixel:.4f}, Pixel std: {std_pixel:.4f}\")\n",
    "    print(f\"Pixel Mean: {mean_pixel:.4f}, Pixel Std: {std_pixel:.4f}\")\n",
    "    \n",
    "    # Display sample images\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.set_title(class_names[labels[i]])\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    logging.info(\"Sample images displayed\")\n",
    "\n",
    "# Run analysis\n",
    "analyze_dataset(train_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Pipeline\n",
    "\n",
    "We create data loaders to preprocess images:\n",
    "- **Resize**: Scale 28×28 images to 224×224 for ResNet50.\n",
    "- **Channel Duplication**: Convert grayscale to 3 channels using `Grayscale(num_output_channels=3)`.\n",
    "- **Augmentation**: Apply random horizontal flips to improve generalization.\n",
    "- **Normalization**: Use ImageNet stats (`mean=[0.485], std=[0.229]`) for pretrained weights.\n",
    "- **Batch Size**: 32 to ensure GPU memory usage stays ~8–10 GB.\n",
    "- **Optimization**: `pin_memory=True` and `num_workers=1` for efficient GPU data transfers.\n",
    "\n",
    "We verify the batch shape to confirm preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_csv, test_csv, batch_size=32):\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
    "    ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = FashionMNISTCSVDataset(train_csv, transform=train_transform)\n",
    "    test_dataset = FashionMNISTCSVDataset(test_csv, transform=test_transform)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    logging.info(f\"Data loaders created with batch size {batch_size}\")\n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, test_loader = get_data_loaders(train_csv, test_csv, batch_size=32)\n",
    "\n",
    "# Verify a batch\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\")  # Expect [32, 3, 224, 224]\n",
    "print(f\"Label shape: {labels.shape}\")  # Expect [32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Setup\n",
    "\n",
    "We load a pretrained ResNet50, freeze its backbone to save GPU memory, and replace the fully connected layer with a custom head:\n",
    "- **Input**: 2048 features from ResNet50’s final layer.\n",
    "- **Head**: Linear(2048, 512) → ReLU → Dropout(0.5) → Linear(512, 10).\n",
    "- **GPU**: Model is moved to GPU with mixed precision enabled for efficiency.\n",
    "\n",
    "The head architecture is displayed for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes=10):\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(512, num_classes)\n",
    "    )\n",
    "    model = model.to(device)\n",
    "    logging.info(\"Model initialized with pretrained ResNet50 and custom head\")\n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = get_model()\n",
    "print(\"Custom head architecture:\")\n",
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Head-Only Training\n",
    "\n",
    "We train only the custom head for up to 10 epochs, keeping the ResNet50 backbone frozen:\n",
    "- **Optimizer**: Adam with learning rate 0.001, weight decay 1e-4.\n",
    "- **Loss**: Cross-entropy for multi-class classification.\n",
    "- **Scheduler**: ReduceLROnPlateau reduces learning rate if validation loss plateaus for 3 epochs.\n",
    "- **Early Stopping**: Stops if validation accuracy doesn’t improve for 5 epochs.\n",
    "- **Mixed Precision**: Reduces GPU memory usage to ~8–10 GB using `torch.cuda.amp`.\n",
    "- **Metrics Display**: Prints training loss, training accuracy, validation loss, validation accuracy, and GPU memory per epoch.\n",
    "\n",
    "### What to Monitor\n",
    "- **Training Loss**: Should decrease steadily.\n",
    "- **Validation Loss**: Should decrease but may rise if overfitting.\n",
    "- **Accuracy Gap**: Large gap (train > val) suggests overfitting.\n",
    "- **GPU Memory**: Should stay ~8–10 GB, well within 16 GB.\n",
    "\n",
    "After training, we plot loss and accuracy curves to visualize convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    val_loss = running_loss / len(loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    return val_loss, val_acc, all_preds, all_labels\n",
    "\n",
    "def train_model(model, train_loader, test_loader, num_epochs=10, fine_tune=False):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001 if not fine_tune else 0.0001, weight_decay=1e-4)\n",
    "    scaler = GradScaler()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "    best_val_acc = 0.0\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    train_losses, train_accs = [], []\n",
    "    val_losses, val_accs = [], []\n",
    "    \n",
    "    # Print header for metrics\n",
    "    print(f\"{'Epoch':<6} {'Train Loss':<12} {'Train Acc':<12} {'Val Loss':<12} {'Val Acc':<12} {'GPU Memory (MB)':<15}\")\n",
    "    print(\"-\" * 67)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "        val_loss, val_acc, preds, labels = evaluate(model, test_loader, criterion)\n",
    "        scheduler.step(val_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Display metrics\n",
    "        gpu_memory = torch.cuda.memory_allocated(device)/1e6 if device.type == \"cuda\" else 0.0\n",
    "        print(f\"{epoch+1:<6} {train_loss:<12.4f} {train_acc:<12.2f} {val_loss:<12.4f} {val_acc:<12.2f} {gpu_memory:<15.2f}\")\n",
    "        \n",
    "        # Log metrics\n",
    "        logging.info(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        logging.info(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        if device.type == \"cuda\":\n",
    "            logging.info(f\"GPU Memory Allocated: {gpu_memory:.2f} MB\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model_head.pth' if not fine_tune else 'best_model_finetune.pth')\n",
    "            logging.info(\"Best model saved\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            logging.info(\"Early stopping triggered\")\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.title(f\"Loss Curves ({'Fine-Tuning' if fine_tune else 'Head-Only'})\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train Accuracy')\n",
    "    plt.plot(val_accs, label='Val Accuracy')\n",
    "    plt.title(f\"Accuracy Curves ({'Fine-Tuning' if fine_tune else 'Head-Only'})\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    logging.info(f\"Training curves plotted ({'fine-tuning' if fine_tune else 'head-only'})\")\n",
    "    \n",
    "    return train_losses, train_accs, val_losses, val_accs, preds, labels\n",
    "\n",
    "# Train head only\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "logging.info(\"Starting head-only training\")\n",
    "print(\"\\nHead-Only Training:\")\n",
    "head_train_losses, head_train_accs, head_val_losses, head_val_accs, head_preds, head_labels = train_model(\n",
    "    model, train_loader, test_loader, num_epochs=10, fine_tune=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Confusion Matrix for Head-Only Training\n",
    "\n",
    "We plot a confusion matrix to analyze the model’s performance on the test set after head-only training. This visualizes which classes are correctly classified and which are confused (e.g., Shirt vs. T-shirt/top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(preds, labels, title):\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    logging.info(f\"Confusion matrix plotted: {title}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(head_preds, head_labels, 'Confusion Matrix (Head-Only Training)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fine-Tuning\n",
    "\n",
    "We load the best model from head-only training, unfreeze the `layer4` block of ResNet50, and fine-tune for up to 10 epochs with a lower learning rate (0.0001):\n",
    "- **Purpose**: Adapt deeper features to Fashion-MNIST while preserving pretrained weights.\n",
    "- **Metrics Display**: Prints the same per-epoch metrics (training/validation loss, accuracy, GPU memory) as head-only training.\n",
    "- **Optimization**: Uses mixed precision and selective unfreezing to keep memory ~8–10 GB.\n",
    "\n",
    "### What to Monitor\n",
    "- **Loss Improvement**: Expect validation loss to decrease further compared to head-only training.\n",
    "- **Accuracy Gain**: Validation accuracy should improve (e.g., from ~85–90% to ~90–93%).\n",
    "- **Overfitting**: Watch for increasing validation loss or a larger train-val accuracy gap.\n",
    "- **GPU Memory**: Should remain stable, slightly higher than head-only due to more trainable parameters.\n",
    "\n",
    "Training curves are plotted to compare with head-only results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model):\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "    logging.info(\"Unfrozen layer4 for fine-tuning\")\n",
    "    return model\n",
    "\n",
    "# Load best head-only model and fine-tune\n",
    "model.load_state_dict(torch.load('best_model_head.pth'))\n",
    "model = fine_tune_model(model)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "logging.info(\"Starting fine-tuning\")\n",
    "print(\"\\nFine-Tuning:\")\n",
    "finetune_train_losses, finetune_train_accs, finetune_val_losses, finetune_val_accs, finetune_preds, finetune_labels = train_model(\n",
    "    model, train_loader, test_loader, num_epochs=10, fine_tune=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Confusion Matrix for Fine-Tuning\n",
    "\n",
    "We plot a confusion matrix for the fine-tuned model to assess improvements in classification performance compared to head-only training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(finetune_preds, finetune_labels, 'Confusion Matrix (Fine-Tuning)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Summary and Experimentation\n",
    "\n",
    "### Results\n",
    "- **Head-Only Training**:\n",
    "  - Expected validation accuracy: ~85–90%.\n",
    "  - Only the custom head was trained, leveraging pretrained features.\n",
    "- **Fine-Tuning**:\n",
    "  - Expected validation accuracy: ~90–93%.\n",
    "  - Improved by adapting `layer4` features to Fashion-MNIST.\n",
    "- **GPU Usage**:\n",
    "  - Peak memory: ~8–10 GB, optimized for 16 GB GPU with mixed precision, batch size 32, and selective unfreezing.\n",
    "  - Verified via per-epoch memory display and logs.\n",
    "\n",
    "### Visualizations\n",
    "- **Class Distribution**: Confirms balanced classes (~6,000 per class).\n",
    "- **Sample Images**: Verifies data integrity and class representation.\n",
    "- **Training Curves**: Shows loss and accuracy trends for head-only and fine-tuning phases.\n",
    "- **Confusion Matrices**: Highlights misclassifications and improvements post-fine-tuning.\n",
    "\n",
    "### Per-Epoch Metrics\n",
    "The displayed metrics (training/validation loss, accuracy, GPU memory) per epoch provide real-time insights:\n",
    "- **Loss Trends**: Decreasing loss indicates learning; divergence suggests overfitting.\n",
    "- **Accuracy Trends**: Rising accuracy shows improvement; large train-val gaps indicate overfitting.\n",
    "- **GPU Memory**: Stable usage (~8–10 GB) confirms optimization.\n",
    "\n",
    "Check the log file (`fashion_mnist_training_YYYYMMDD_HHMMSS.log`) for detailed records.\n",
    "\n",
    "### Experimentation Ideas\n",
    "Based on observed metrics, try the following:\n",
    "- **Augmentation**: Add `transforms.RandomRotation(10)` to `train_transform` if underfitting (low accuracy):\n",
    "  ```python\n",
    "  train_transform = transforms.Compose([\n",
    "      transforms.Resize((224, 224)),\n",
    "      transforms.Grayscale(num_output_channels=3),\n",
    "      transforms.RandomHorizontalFlip(p=0.5),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
    "  ])\n",
    "  ```\n",
    "- **Dropout**: Reduce to 0.3 or increase to 0.7 in `get_model` if overfitting (large train-val gap):\n",
    "  ```python\n",
    "  model.fc = nn.Sequential(\n",
    "      nn.Linear(in_features, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(0.3),  # Adjust here\n",
    "      nn.Linear(512, num_classes)\n",
    "  )\n",
    "  ```\n",
    "- **Weight Decay**: Test 5e-4 or 1e-3 in `train_model` to reduce overfitting:\n",
    "  ```python\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.001 if not fine_tune else 0.0001, weight_decay=5e-4)\n",
    "  ```\n",
    "- **Image Size**: Use 112×112 to save memory if GPU usage is high:\n",
    "  ```python\n",
    "  transforms.Resize((112, 112))\n",
    "  ```\n",
    "- **Batch Size**: Reduce to 16 if memory errors occur:\n",
    "  ```python\n",
    "  train_loader, test_loader = get_data_loaders(train_csv, test_csv, batch_size=16)\n",
    "  ```\n",
    "\n",
    "### Debugging Tips\n",
    "- **High Validation Loss**: Increase `patience` in `train_model` or adjust learning rate.\n",
    "- **Low Accuracy**: Train for more epochs (`num_epochs=15`) or add augmentation.\n",
    "- **Memory Issues**: Check GPU memory in per-epoch display; reduce batch size or image size if >12 GB.\n",
    "\n",
    "The best models are saved as `best_model_head.pth` and `best_model_finetune.pth` for further evaluation or deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
